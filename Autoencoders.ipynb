{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 15 Autoencoders\n",
    "\n",
    "Autoencoders attempt to reproduce their input as output, but under certain limiting conditions which end up making them useful. Because of these constraints, they end up learning more efficient representations of the data. This makes them useful for dimensionality reduction, feature extraction, unsupervised pretraining of DNNs, and for generating novel data which resembles the input they were trained on. \n",
    "\n",
    "## Efficient Data Representations\n",
    "\n",
    "An autoencoder is made up an *encoder*, also called a *recognition network*, which transforms the data into an alternate representation, and a *decoder* or *generative network* which attempts to reproduce the original input. This output is called a *reconstruction*, and the the autoencoder's associated cost function is a measure of the difference between the original input and the reconstructed output. When the the new representation has fewer dimensions than the original data, the autoencoder is called *undercomplete*. \n",
    "\n",
    "## Performing PCA with an Undercomplete Linear Autoencoder\n",
    "\n",
    "It turns out that an autoencoder with linear activations and an MSE cost function is equivalent to PCA! Let's build that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Generate data\n",
    "m = 200\n",
    "w1, w2 = 0.1, 0.3\n",
    "noise = 0.1\n",
    "\n",
    "angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
    "data = np.empty((m, 3))\n",
    "data[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m) / 2\n",
    "data[:, 1] = np.sin(angles) * 0.7 + noise * np.random.randn(m) / 2\n",
    "data[:, 2] = data[:, 0] * w1 + data[:, 1] * w2 + noise * np.random.randn(m)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(data[:100])\n",
    "X_test = scaler.transform(data[100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-b67fcdc28a1d>:8: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "n_inputs = 3\n",
    "n_hidden = 2\n",
    "n_outputs = n_inputs\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
    "hidden = tf.layers.dense(X, n_hidden)\n",
    "outputs = tf.layers.dense(hidden, n_outputs)\n",
    "\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "codings = hidden\n",
    "\n",
    "n_iterations = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in np.arange(n_iterations):\n",
    "        training_op.run(feed_dict={X: X_train})\n",
    "    codings_val = codings.eval(feed_dict={X: X_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this is just like the networks we have built in the past but with certain constraints (most importantly, the number of outputs is equal to the number of inputs).\n",
    "\n",
    "## Stacked Autoencoders\n",
    "\n",
    "Stacked autoencoders are autoencoders with multiple hidden layers. The layers are usually symmetric in terms of size about the middle layer. Let's make a stacked autoencoder for the MINST dataset using He initialization, ELU activation, and l2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-4141630e56b4>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 150 # middle layer\n",
    "n_hidden3 = n_hidden1\n",
    "n_outputs = n_inputs\n",
    "\n",
    "learning_rate = 0.01\n",
    "l2_reg = 0.0001\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X')\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "l2_regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
    "dense_layer = partial(tf.layers.dense, \n",
    "                     activation=tf.nn.elu,\n",
    "                     kernel_initializer=he_init,\n",
    "                     kernel_regularizer=l2_regularizer)\n",
    "\n",
    "hidden1 = dense_layer(X, n_hidden1)\n",
    "hidden2 = dense_layer(hidden1, n_hidden2)\n",
    "hidden3 = dense_layer(hidden2, n_hidden3)\n",
    "outputs = dense_layer(hidden3, n_outputs, activation=None)\n",
    "\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs-X))\n",
    "\n",
    "reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "loss = tf.add_n([reconstruction_loss] + reg_losses)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MSE: 0.016553189605474472\n",
      "1 MSE: 0.010354864411056042\n",
      "2 MSE: 0.010610595345497131\n",
      "3 MSE: 0.010916679166257381\n",
      "4 MSE: 0.010924546979367733\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 100\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in np.arange(n_epochs):\n",
    "        n_batches = mnist.train.num_examples // batch_size\n",
    "        for _ in np.arange(n_batches):\n",
    "            X_batch, _ = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch})\n",
    "        training_loss = reconstruction_loss.eval(feed_dict={X: X_batch})\n",
    "        print(f'{epoch} MSE: {training_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tying Weights\n",
    "\n",
    "We can speed up training and reduce overfitting by *tying the weights* of a symmetrical model. This means we will only train the weights in the layers of the first half of the autoencoder, and using the transpose of the weight matrix to define the weights in the corresponding layer in the last half of our network. Instead of using tf.layers.dense, we will have to define our network more manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = tf.nn.elu\n",
    "regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
    "initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
    "\n",
    "weights1_init = initializer([n_inputs, n_hidden1])\n",
    "weights2_init = initializer([n_hidden1, n_hidden2])\n",
    "\n",
    "weights1 = tf.Variable(weights1_init, dtype=tf.float32, name=\"weights1\")\n",
    "weights2 = tf.Variable(weights2_init, dtype=tf.float32, name=\"weights2\")\n",
    "weights3 = tf.transpose(weights2, name=\"weights3\")  # tied weights\n",
    "weights4 = tf.transpose(weights1, name=\"weights4\")  # tied weights\n",
    "\n",
    "# Biases are not tied \n",
    "biases1 = tf.Variable(tf.zeros(n_hidden1), name=\"biases1\")\n",
    "biases2 = tf.Variable(tf.zeros(n_hidden2), name=\"biases2\")\n",
    "biases3 = tf.Variable(tf.zeros(n_hidden3), name=\"biases3\")\n",
    "biases4 = tf.Variable(tf.zeros(n_outputs), name=\"biases4\")\n",
    "\n",
    "hidden1 = activation(tf.matmul(X, weights1) + biases1)\n",
    "hidden2 = activation(tf.matmul(hidden1, weights2) + biases2)\n",
    "hidden3 = activation(tf.matmul(hidden2, weights3) + biases3)\n",
    "outputs = tf.matmul(hidden3, weights4) + biases4\n",
    "\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\n",
    "# Only regularize weights we train\n",
    "reg_loss = regularizer(weights1) + regularizer(weights2)\n",
    "loss = reconstruction_loss + reg_loss\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training One Autoencoder at a Time\n",
    "\n",
    "Instead of training the entire autoencoder at once, we can instead train one layer at a time in its own graph, and stack them on top of each other once we've finished training. Each new autoencoder or layer will try to learn the output of the previous one, with the first trying to learn the inputs. In TensorFlow, this corresponds to building an autoencoder, feeding it your training set, and using its output as the training set for the next layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def train_autoencoder(X_train, n_neurons, n_epochs, batch_size,\n",
    "                     learning_rate=0.01, l2_reg=0.0005,\n",
    "                     hidden_activation=tf.nn.elu,\n",
    "                     output_activation=tf.nn.elu):\n",
    "    \n",
    "    graph = tf.Graph()\n",
    "    \n",
    "    with graph.as_default():\n",
    "        \n",
    "        n_inputs = X_train.shape[1]\n",
    "        \n",
    "        X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "        \n",
    "        dense_layer = partial(tf.layers.dense, \n",
    "                              kernel_initializer=tf.contrib.layers.variance_scaling_initializer(), \n",
    "                              kernel_regularizer=tf.contrib.layers.l2_regularizer(l2_reg))\n",
    "        \n",
    "        hidden = dense_layer(X, n_neurons, activation=hidden_activation, name='hidden')\n",
    "        outputs = dense_layer(hidden, n_inputs, activation=None, name='outputs')\n",
    "                              \n",
    "        reconstruction_loss = tf.reduce_mean(tf.square(outputs-X))    \n",
    "        reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "        loss = tf.add_n([reconstruction_loss] + reg_losses)\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        init.run()\n",
    "        for epoch in np.arange(n_epochs):\n",
    "            n_batches = len(X_train) // batch_size\n",
    "            for iteration in np.arange(n_batches):\n",
    "                batch_indices = np.random.permutation(len(X_train))[:batch_size]\n",
    "                X_batch = X_train[batch_indices]\n",
    "                sess.run(training_op, feed_dict={X: X_batch})\n",
    "            training_loss = reconstruction_loss.eval(feed_dict={X: X_batch})\n",
    "            print(f'{epoch} MSE: {training_loss}')\n",
    "            \n",
    "        saver.save(sess, 'models/mnist_autoencoder.ckpt')\n",
    "            \n",
    "        # Grab all parameters after model is trained\n",
    "        params = dict([(var.name, var.eval()) for var in tf.get_collection(\n",
    "        tf.GraphKeys.TRAINABLE_VARIABLES)])\n",
    "        # Get output of hidden layer\n",
    "        hidden_output = hidden.eval(feed_dict={X: X_train})\n",
    "        # Return output and trained weights/biases\n",
    "        return hidden_output, params[\"hidden/kernel:0\"], params[\"hidden/bias:0\"], params[\"outputs/kernel:0\"], params[\"outputs/bias:0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MSE: 0.018513096496462822\n",
      "1 MSE: 0.018578777089715004\n",
      "2 MSE: 0.019105955958366394\n",
      "3 MSE: 0.019317802041769028\n",
      "0 MSE: 0.004438340663909912\n",
      "1 MSE: 0.004384850617498159\n",
      "2 MSE: 0.00440275389701128\n",
      "3 MSE: 0.004439910873770714\n"
     ]
    }
   ],
   "source": [
    "# Train 1st layer to reproduce input and grab its output\n",
    "hidden_output, W1, b1, W4, b4 = train_autoencoder(mnist.train.images, n_neurons=300, \n",
    "                                                  n_epochs=4, batch_size=150,\n",
    "                                                  output_activation=None)\n",
    "# Train 2nd layer to reproduce output from 1st layer\n",
    "_, W2, b2, W3, b3 = train_autoencoder(hidden_output, n_neurons=150, n_epochs=4, batch_size=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined the weights and biases of each layer, we can use them to manually construct our entire autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_inputs = 28*28\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
    "hidden1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "hidden2 = tf.nn.elu(tf.matmul(hidden1, W2) + b2)\n",
    "hidden3 = tf.nn.elu(tf.matmul(hidden2, W3) + b3)\n",
    "outputs = tf.matmul(hidden3, W4) + b4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image, shape=[28, 28]):\n",
    "    plt.imshow(image.reshape(shape), cmap=\"Greys\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def show_reconstructed_digits(X, outputs, model_path = None, n_test_digits = 2):\n",
    "    with tf.Session() as sess:\n",
    "        if model_path:\n",
    "            saver.restore(sess, model_path)\n",
    "        X_test = mnist.test.images[:n_test_digits]\n",
    "        outputs_val = outputs.eval(feed_dict={X: X_test})\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 3 * n_test_digits))\n",
    "    for digit_index in range(n_test_digits):\n",
    "        plt.subplot(n_test_digits, 2, digit_index * 2 + 1)\n",
    "        plot_image(X_test[digit_index])\n",
    "        plt.subplot(n_test_digits, 2, digit_index * 2 + 2)\n",
    "        plot_image(outputs_val[digit_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_reconstructed_digits(X, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Pretraining\n",
    "\n",
    "We can also use undercomplete autoencoders to pretrain lower layers for a neural network when we have don't have very much labelled data. This process is similar to what we did in an earlier chapter, where we froze the layers of a pretrained model. In this case, the autoencoder will be trained on the unlabelled data, its layers will be frozen, and we will train a neural network using these lower layers on the labelled data.\n",
    "\n",
    "## Denoising Autoencoders\n",
    "\n",
    "Instead of using undercomplete autoencoders to learn important features, we can also use coding layers that are as larger or larger than the input layers (an *overcomplete* autoencoder) for different sorts of tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
